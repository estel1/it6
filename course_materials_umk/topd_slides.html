<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
    <style>
		body {
		  background: rgb(0,74,134); 
		}
		page {
		  background: white;
		  display: block;
		  margin: .5cm auto;
		  box-shadow: 0 0 0.5cm rgba(0,0,0,0.5);
		}
		page[size="A5"] {  
		  width: 21cm;
		  height: 14.8cm; 
		}
		page[size="A4"] {  
		  width: 21cm;
		  height: 29.7cm; 
		}
		page[size="A4"][layout="portrait"] {
		  width: 29.7cm;
		  height: 21cm;  
		}
		@media print {
		  body, page {
			margin: 0;
			box-shadow: 0;
		  }
		}
		header {
			padding: 0 0 0 0 ;
			color: white;
			background-color: rgb(0,130,200) ;
			clear: bottom;
			text-align: left;
		}
		
		.header {
			border:1px solid darkgray ;
		}

		.header .image {
			background: url("https://www.mirea.ru/images/logo_mgupi.png") no-repeat;
			width: 100px;
			height: 90px;
			border:0px solid green;
		}

		.header .text {
			font: x-large Times New Roman ;
			border:0px solid blue;
		}

		.header .image, 
		.header .text {
			display: inline-block;
			vertical-align: middle;
		}
		.body {
			margin : 5px ;
		}
	</style>
	<script type="text/javascript" async
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
		TeX: { equationNumbers: { autoNumber: "AMS" } }
		});
	</script>
</head>
<body>

    <page size="A5">
		<header>
			<div class="header">
				<div class="image"></div><div class="text"><font size="7">Entropy</font><BR><font size="6">Энтропия дискретного источника.</font></div>
			</div>		
		</header>
		<div class="body">
		Энтропия \(H\) дискретного источника может быть представлена в виде[1]:
		\begin{equation}
			H = -K\sum_{i=1}^{n}p_i\log p_i
		  \label{Entropy}
		\end{equation}	
		Для случая когда источник генерирует одно из двух возможных сообщений:
		\begin{equation}
			H = -K(p \log p + q\log q)
		  \label{Entropy2}
		\end{equation}	
		</div>
		<img src="http://www5a.wolframalpha.com/Calculate/MSP/MSP64881c1beadd87fgid890000641i4befa63ae3e7?MSPStoreType=image/gif&s=52&w=300.&h=183.&cdf=RangeControl" align="middle">

		<div class="footer">1. C. E. Shannon, Bell Syst. Tech. J. 27, 379 (1948). </div>		
   </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Entropy</font><BR><font size="6">Совместная энтропия.</font></div>
		</div>		
	</header>	
		Энтропия \(H(x,y)\) двух источников:
		\begin{equation}
			H(x,y) = -\sum_{i,j}p(i,j)\log p(i,j)
		  \label{Entropyxy}
		\end{equation}	
		\begin{equation}
			H(x) = -\sum_{i,j}p(i,j)\log \sum_{j} p(i,j)
		  \label{Entropy_x}
		\end{equation}	
		\begin{equation}
			H(y) = -\sum_{i,j}p(i,j)\log \sum_{i} p(i,j)
		  \label{Entropy_y}
		\end{equation}	
		И
		\begin{equation}
			H(x,y) \leq H(x)+H(y)
		\end{equation}	
		Равенство \(H(x,y) = H(x)+H(y)\) выполняется когда \(x\) и \(y\) независимы.
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Entropy</font><BR><font size="6">Условная энтропия.</font></div>
		</div>		
	</header>	
	    Вероятность того, что переменная \(y\) примет значение \(j\) при условии, что переменная \(x\) приняла значение \(i\):
		\begin{equation}
			p_i(j)=\frac{p(i,j)}{\sum_{j}p(i,j)}
		\end{equation}			
		Условная энтропия \(H_x(y)\) :
		\begin{aligned}
			H_x(y) = -\sum_{i,j}p(i,j)\log p_i(j)=-\sum_{i,j}p(i,j)\log \frac{p(i,j)}{\sum_{j}p(i,j)}= \\
			-\sum_{i,j}p(i,j)\log p(i,j)+\sum_{i,j}p(i,j)\log \sum_{j}p(i,j)=\\
			H(x,y)-H(x)
		\end{aligned}	
	    Таким образом
		\begin{equation}
			H(x,y) = H_x(y) + H(x)
		\end{equation}					
		Условная энтропия показывает меру неопределенности \(y\) при условии, что \(x\) известно.
		\begin{equation}
			H(x)+H(y) \geq H(x,y)=H_x(y) + H(x) \\
		\end{equation}					
		\begin{equation}
			H(y) \geq H_x(y)
		\end{equation}					
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Capacity</font><BR><font size="6">Пропускная способность канала с шумом.</font></div>
		</div>		
	</header>	
	    Скорость передачи:
		\begin{equation}
			R = H(x) - H_x(y)
		\end{equation}			
		Пропускная способность канала с шумом:
		\begin{equation}
			С = \max_{x}(H(x)-H_y(x))
		\end{equation}					
		Здесь максимум определяется среди всех возможных \(x\).
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="6">Continuous</font><BR><font size="6">Энтропия непрерывного распределения.</font></div>
		</div>		
	</header>	
	    Энтропия непрерывного распределения:
		\begin{equation}
			H(x) = -\int\limits_{-\infty}^{\infty}p(x)\log p(x) dx
		\end{equation}			
		Для многомерной плотности \(p(x_1,x_2,\ldots x_n)\)
		\begin{equation}
			H = -\int\limits_{-\infty}^{\infty}\ldots \int\limits_{-\infty}^{\infty} (p(x_1,x_2,\ldots x_n)\log p(x_1,x_2,\ldots x_n) dx
		\end{equation}			
		Совместная энтропия двух непрерывных распределений:
		\begin{equation}
			H(x,y) = -\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log p(x,y) dxdy
		\end{equation}					
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Continuous</font><BR><font size="6">Условная энтропия непрерывного распределения.</font></div>
		</div>		
	</header>	
		Условная энтропия непрерывного распределения
		\begin{equation}
			H_y(x) = -\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log \frac{p(x,y)}{p(x)} dxdy
		\end{equation}					
		\begin{equation}
			H_x(y) = -\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log \frac{p(x,y)}{p(y)} dxdy
		\end{equation}					
		Здесь
		\begin{equation}
			p(x) = -\int\limits_{-\infty}^{\infty}p(x,y) dy
		\end{equation}					
		\begin{equation}
			p(y) = -\int\limits_{-\infty}^{\infty}p(x,y) dx
		\end{equation}					
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Continuous Rate</font><BR><font size="6">Скорость непрерывного канала.</font></div>
		</div>		
	</header>	
	    Рассматриваются сигналы ограниченные в полосе \(W\). Такие сигналы могут быть однозначно представлены \(n=2TW\) отсчетами во времени.
 	    \begin{equation}
		P(x_1,x_2, \ldots x_n) = P(x)
		\end{equation}
		Скорость передачи
		\begin{equation}
			R = H(x) - H_x(y)
		\end{equation}			
		\begin{equation}
			R = -\int\limits_{-\infty}^{\infty}p(x)\log p(x) dx + \int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log \frac{p(x,y)}{p(x)} dxdy=\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log \frac{p(x,y)}{p(x)p(y)} dxdy
		\end{equation}			
		Так как 
		\begin{equation}
			\int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}p(x,y)\log p(x) dxdy=\int\limits_{-\infty}^{\infty}p(x)\log p(x)
		\end{equation}			
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Continuous Capacity</font><BR><font size="6">Пропускная способность непрерывного канала.</font></div>
		</div>		
	</header>	
		Пропускная способность :
		  \begin{equation}
			С=\lim_{T \infty}\max_{P(x)} \frac{1}{T}\int\limits_{X}\int\limits_{Y}p(x,y)\log_2\frac{p(x,y)}{p(x)p(y)}dxdy
			\label{Cap1}
		  \end{equation}	
		  Максимум в формуле (\ref{Cap1}) определяется среди всех возможных распределений \(P(x)\) 
		  (среди всех возможных сигнально-кодовых конструкций).	
    </page>

    <page size="A5">
	<header>
		<div class="header">
			<div class="image"></div><div class="text"><font size="7">Average power limitation</font><BR><font size="6">Сигнал с ограничением средней мощности.</font></div>
		</div>		
	</header>	
		Для случая белого гауссовского шума со спектральной плотностью \(N\) и сигнала с ограниченной средней мощностью \(P\) в полосе \(W\) энтропии выражаются следующим образом.
		  \begin{equation}
		  H(y) = W\log 2\pi e(P+N)
		  \end{equation}			
		  \begin{equation}
		  H(n) = W\log 2\pi e N
		  \end{equation}		
          Пропускная способность
		  \begin{equation}
		  С = H(y)-H(n) = W \log \frac{P+N}{N}
		  \end{equation}		
		  
    </page>
	
    <page size="A5">
		<header>
			<div class="header">
				<div class="image"></div><div class="text"><font size="7">Passband signal</font><BR><font size="6">Полосовая модуляция.</font></div>
			</div>		
		</header>
		<div class="body">
			Сигнал \(s=(s_1,s_2, \ldots s_n)\) ограниченный в полосе \(W\) может быть однозначно представлен \(n=2WT\) символами на интервале \(T\). Расположение этого участка на частотной оси не влияет на пропускную способность. 
			Пусть центральная частота равна \(\omega_0\)
			
			<iframe frameborder="0" style="width:100%;height:200px;" src="https://www.draw.io/?lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1&title=passband%20spectre.xml#Uhttps%3A%2F%2Fraw.githubusercontent.com%2Festel1%2Fit6%2Fmaster%2Fcourse_materials_umk%2Fpassband%2520spectre.xml"></iframe>
			
			Известно, что последовательность длины \(n\) может быть однозначно представлена \(n\) коэффициентами Фурье (в предположении что она периодическая). Так как сигнал \(s\) имеет
			ненулевую мощность лишь в указанной полосе, то и все компонеты спектра должны принадлежать той же области. Для этого каждую компоненту разложения Фурье необходимо сдвинуть 
			по частоте на \(\omega_0\), т.е. вместо \(e^{-j\omega m}\) следует использовать \(e^{-j(\omega+\omega_0)m}=e^{-j\omega m}e^{-j\omega_0 m}\).
		</div>
   </page>

</body>
</html>